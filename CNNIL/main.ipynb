{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a replication/exploration of the paper listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..') # Stupid thing Python makes you do to import from a sibling directory\n",
    "from gen_utils.sr_gen import sr_gen # Custom class for image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNIL(nn.Module):\n",
    "    def __init__(self, upscale=2, axs = 'hw'):\n",
    "        super().__init__()\n",
    "        self.axs = axs\n",
    "\n",
    "        if axs == 'hw':\n",
    "            self.conv1 = nn.Conv2d(1,32,3, bias=False)\n",
    "            self.conv2 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv3 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv4 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv5 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv6 = nn.Conv2d(32,4,3, bias=False)\n",
    "            \n",
    "            # Upscale step occurs here\n",
    "\n",
    "            self.conv7 = nn.Conv2d(1,32,3, bias=False)\n",
    "            self.conv8 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv9 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv10 = nn.Conv2d(32,1,3, bias = False)\n",
    "        elif axs == 'h' or axs == 'w':\n",
    "            self.conv1 = nn.Conv2d(1,32,3,bias=False)\n",
    "            self.conv2 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv3 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv4 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv5 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv6 = nn.Conv2d(32,2,3, bias=False)\n",
    "            \n",
    "            # Upscale step occurs here\n",
    "\n",
    "            self.conv7 = nn.Conv2d(1,32,3, bias=False)\n",
    "            self.conv8 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv9 = nn.Conv2d(32,32,3, bias=False)\n",
    "            self.conv10 = nn.Conv2d(32,1,3, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = nn.ReLU(self.conv1(x))\n",
    "        \n",
    "        x_l = nn.ReLU(self.conv2(x_l))\n",
    "        x_l = nn.ReLU(self.conv3(x_l))\n",
    "        x_l = nn.ReLU(self.conv4(x_l+x))\n",
    "        x_l = nn.ReLU(self.conv5(x_l))\n",
    "        x_l = nn.ReLU(self.conv6(x_l+x))\n",
    "\n",
    "        x_l = self.kern_upscale(x_l, self.axs)\n",
    "\n",
    "        x = nn.ReLU(self.conv7(x_l))\n",
    "        x_h = nn.ReLU(self.conv8(x_h))\n",
    "        x_h = nn.ReLU(self.conv9(x_h))\n",
    "        x_h = nn.ReLU(self.conv10(x_h+x))\n",
    "\n",
    "        return x_l, x_h #Return both results for the loss function\n",
    "\n",
    "\n",
    "    def kern_upscale(x, axs='hw'):\n",
    "        # Function to do the unique upscaling pattern they propose in\n",
    "        # the paper\n",
    "        #TODO: have them input a tuple for scale of the dimensions they wish to expand along\n",
    "        s, c, h, w = x.shape\n",
    "\n",
    "        if axs == 'hw':\n",
    "            c = c/2\n",
    "            x_up = torch.cat(torch.unbind(x,1),2)\n",
    "            x_up = torch.reshape(x_up,(s,1,h*c,w*c))\n",
    "            x_up = torch.transpose(x_up,2,3)\n",
    "            x_up = torch.cat(torch.split(x_up,2,2),3)\n",
    "            x_up = torch.transpose(torch.reshape(x_up,(s,1,h*c,w*c)),2,3)\n",
    "        elif axs == 'h':\n",
    "            x_up = torch.cat(torch.unbind(x,2),1)\n",
    "            #x_up = torch.unsqueeze(x_up,0)\n",
    "        elif axs == 'w':\n",
    "            x_up = torch.cat(torch.unbind(x,3),1)\n",
    "            x_up = torch.transpose(x_up,1,2)\n",
    "            #x_up = torch.unsqueeze(x_up,0)\n",
    "        else:\n",
    "            print('No valid scaling dimension selected, returning False')\n",
    "            x_up = False\n",
    "\n",
    "        return x_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing of kern_upscale function with only 3D tensor\n",
    "\n",
    "a = torch.tensor([[[1,2],[3,4]],\n",
    "                [[5,6],[7,8]],\n",
    "                [[9,10],[11,12]],\n",
    "                [[13,14],[15,16]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 2])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  5,  2,  6],\n",
       "        [ 9, 13, 10, 14],\n",
       "        [ 3,  7,  4,  8],\n",
       "        [11, 15, 12, 16]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinate each of the layers next to eachother\n",
    "print(a.shape)\n",
    "b = torch.cat(torch.unbind(a),1)\n",
    "print(b.shape)\n",
    "b = torch.reshape(b,(4,4))\n",
    "print(b.shape)\n",
    "b = torch.transpose(b,0,1)\n",
    "b = torch.cat(torch.split(b,2,0),1)\n",
    "torch.transpose(torch.reshape(b,(4,4)),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a is torch.Size([1, 4, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  5,  2,  6],\n",
       "          [ 9, 13, 10, 14],\n",
       "          [ 3,  7,  4,  8],\n",
       "          [11, 15, 12, 16]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing of above kern_upscale function with 4D tensor (what the model will acually use)\n",
    "a = torch.tensor([[[[1,2],[3,4]],\n",
    "                [[5,6],[7,8]],\n",
    "                [[9,10],[11,12]],\n",
    "                [[13,14],[15,16]]]])\n",
    "print(f'shape of a is {a.shape}')\n",
    "\n",
    "b = torch.cat(torch.unbind(a,1),2)\n",
    "b = torch.reshape(b,(1,1,4,4))\n",
    "b = torch.transpose(b,2,3)\n",
    "b = torch.cat(torch.split(b,2,2),3)\n",
    "b = torch.transpose(torch.reshape(b,(1,1,4,4)),2,3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a is torch.Size([1, 2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upscale along just one axis\n",
    "a = torch.tensor([[[[1,2],[3,4]],\n",
    "                [[5,6],[7,8]]]])\n",
    "print(f'shape of a is {a.shape}')\n",
    "\n",
    "# Version for doubling height\n",
    "b = torch.cat(torch.unbind(a,2),2)\n",
    "b = torch.reshape(b,(1,1,2,4))\n",
    "b = torch.cat(torch.split(b,2,3),2)\n",
    "# b = torch.unsqueeze(torch.cat(torch.unbind(a,2),1),0)\n",
    "\n",
    "\n",
    "# Version for doubling width\n",
    "# b = torch.cat(torch.unbind(a,3),1)\n",
    "# b = torch.transpose(b, 1,2)\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = CNNIL(axs = 'hw')\n",
    "net_2 = CNNIL(axs = 'w')\n",
    "\n",
    "# \"... trained the CNN for 40 epochs, starting with a learning rate of 0.001 and decreasing\n",
    "# the learning rate to 0.0001 after the first 20 epochs\"\n",
    "optimizer_1 = optim.Adam(net_1.parameters(), lr=0.001)\n",
    "optimizer_2 = optim.Adam(net_2.parameters(), lr=0.001)\n",
    "\n",
    "# They have a custom loss function that incorporates the final results and the result\n",
    "# right after the upscaling step\n",
    "# https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
    "\n",
    "def intermediate_loss(output_intermediate, output_final, target):\n",
    "    mae_loss = nn.L1Loss() #Built in mean absolute error loss function\n",
    "    loss = mae_loss(output_intermediate, target)+mae_loss(output_final, target)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_train = sr_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sr_train.get_template()\n",
    "temp[\"patch\"] = 20\n",
    "\n",
    "sr_train.save_template(temp)\n",
    "\n",
    "sr_train.run(clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sr_class):\n",
    "        self.sr_class = sr_class\n",
    "\n",
    "        # In case I forget to run match_altered before pulling the class\n",
    "        if not sr_class.HR_files:\n",
    "            sr_class.match_altered(update=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sr_class.HR_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Y, X = self.sr_class.load_image_pair(index)\n",
    "        X = torch.unsqueeze(torch.tensor(X, dtype=torch.float32),0)\n",
    "        Y = torch.unsqueeze(torch.tensor(Y, dtype=torch.float32),0)\n",
    "\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 3}\n",
    "\n",
    "training_set = Dataset(sr_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "max_epochs = 20\n",
    "save_rate = 5\n",
    "epoch_adjust = 0\n",
    "save_prefix = \"./CNNIL_save_\"\n",
    "\n",
    "mean_loss = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    losses = []\n",
    "\n",
    "    ###### Test running this code where each epoch a new set of random images is made\n",
    "    sr_train.run(clear=True)\n",
    "\n",
    "    training_set = Dataset(sr_train)\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "    ######\n",
    "\n",
    "\n",
    "    # Training\n",
    "    count = 0\n",
    "    for inp, goal in training_generator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(inp,2) # the 2 is the number of iterations in the LISTA network\n",
    "        output = torch.clamp(output, 0, 255)\n",
    "\n",
    "        loss = criterion(output,goal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        #print(f'mini-batch # {count}, mean loss = {sum(losses)/len(losses)}')\n",
    "        count = count+1\n",
    "\n",
    "    if (epoch % save_rate == 0) or epoch == (max_epochs-1):\n",
    "        torch.save(net.state_dict(), f'{save_prefix}{epoch+epoch_adjust}.p')\n",
    "    print(f'\\n\\n epoch {epoch}, loss mean: {sum(losses)/len(losses)}, loss: {min(losses)}-{max(losses)}\\n')\n",
    "    mean_loss.append(sum(losses)/len(losses))\n",
    "\n",
    "    # Give computer time to cool down\n",
    "    time.sleep(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
