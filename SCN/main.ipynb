{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Robust Single Image Super-Resolution via Deep Networks with Sparse Prior](https://ieeexplore.ieee.org/document/7466062)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a replication/exploration of the paper linked above. Data was tested on the ABIDEII-BNI1 anatomical scans (subjects 29006 - 29011 for training, 29012 - 29015 for testing). This data can be found [here](http://fcon_1000.projects.nitrc.org/indi/abide/abide_II.html) in the Barrow Neurological Institute `Scan Data` link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "There is an assumed organization of the MRI files from ABIDEII-BNI1 in this exercise with respect to this folder. If you have these files in the correct folder, you should receive the same (or similar) results. The files are not provided in this repository for file size reasons. If this is not the case for you, change the references to these files in `SrGen` in the following code to the correct locations.\n",
    "\n",
    "```\n",
    "../data/CNNIL_nifti/\n",
    "                Raw_train/\n",
    "                    subject_29006.nii\n",
    "                    subject_29007.nii\n",
    "                    subject_29008.nii\n",
    "                    subject_29009.nii\n",
    "                    subject_29010.nii\n",
    "                    subject_29011.nii\n",
    "                Raw_test/\n",
    "                    subject_29012.nii\n",
    "                    subject_29013.nii\n",
    "                    subject_29014.nii\n",
    "                    subject_29015.nii\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Like all good python scripts, we import a couple libraries. Note the importing of my own custom class `SrGen` for data loading/saving/organization. That is also in this repository, see the `/gen_utils/SrGen.py` for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from gen_utils.SrGen import SrGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN(nn.Module):\n",
    "    def __init__(self,sy,sg):\n",
    "        super().__init__()\n",
    "        C = 5\n",
    "        L = 5\n",
    "\n",
    "        Dx = torch.normal(0,1, size = (25,128))\n",
    "        Dy = torch.normal(0,1, size = (100,128))\n",
    "        I = torch.eye(128)\n",
    "\n",
    "        self.conv = nn.Conv2d(1,100,9, bias = False, stride =1, padding = 6, padding_mode='reflect')\n",
    "        self.mean2 = nn.Conv2d(1,1,13, bias = False, stride = 1, padding = 6, padding_mode='reflect')\n",
    "        self.diffms = nn.Conv2d(1,25,9, bias=False, stride = 1, padding=6, padding_mode='reflect')\n",
    "\n",
    "        self.wd = nn.Conv2d(100,128,1,bias = False, stride = 1)\n",
    "        self.usd1 = nn.Conv2d(128, 128, 1, bias = False, stride=1)\n",
    "        self.ud = nn.Conv2d(128,25,1,bias=False,stride=1)\n",
    "        self.addp = nn.Conv2d(16,1,1, bias = False, stride = 1)\n",
    "\n",
    "        self.mean2.weight = torch.nn.Parameter(self.create_gaus(13), requires_grad = False)\n",
    "        self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "        self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T), requires_grad=True)\n",
    "        self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)), requires_grad=True)\n",
    "        self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx), requires_grad=True)\n",
    "        self.addp.weight = torch.nn.Parameter(torch.ones(1,16,1,1)*0.06, requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, k, sy=9, sg=5):\n",
    "        #print(f'input: {x.min()}-{x.max()}')\n",
    "        x = x+0.1\n",
    "\n",
    "        im_mean = self.mean2(x)\n",
    "        # print(f'im_mean shape {im_mean.shape}')\n",
    "        diffms = self.diffms(x)\n",
    "        # print(f'diffms shape: {diffms.shape}')\n",
    "\n",
    "        n, c, h, w = x.shape\n",
    "        # y = torch.zeros(n, 100, h-8, w-8)\n",
    "        x = self.conv(x)\n",
    "        # print(f'post conv shape {x.shape}')\n",
    "        #print(f'conv max {x.max()}')\n",
    "        #x=x+1\n",
    "\n",
    "        x = x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True)\n",
    "        # print(f'post vector norm shape: {x.shape}')\n",
    "        #print(f'postnorm max {x.max()}')\n",
    "\n",
    "        x = self.wd(x)\n",
    "        #print(f'conv wd {x.max()}')\n",
    "        z = self.ShLU(x,1)\n",
    "        #print(f'conv SHLU {x.max()}')\n",
    "\n",
    "        # Go through LISTA\n",
    "        for i in range(k):\n",
    "            z = self.ShLU(self.usd1(z)+x,1)\n",
    "\n",
    "        x = self.ud(z)\n",
    "        #print(f'ud max {x.max()}')\n",
    "        # print(f'post ud shape {x.shape}')\n",
    "        x = (x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True))*torch.linalg.vector_norm(diffms, ord=2, dim=1, keepdim=True)*1.1\n",
    "        # print(f'prereassembled x shape {x.shape}')\n",
    "        x = self.reassemble2(x,im_mean,4)\n",
    "        # print(f'reassembled x shape {x.shape}')\n",
    "        x = self.addp(x)\n",
    "        #print(f'x.reassemble.max = {x.max()}')\n",
    "        x = x+im_mean\n",
    "\n",
    "        #print(f'output: {x.min()}-{x.max()}')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reassemble2(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        \n",
    "        # img_stack=torch.zeros(s,25,h,w)\n",
    "        img_stack=torch.zeros(s,16,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    img_stack[q,filt,:,:] = x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack\n",
    "    \n",
    "    def create_diffms(self, kern_size, sy=5):\n",
    "        diffms = torch.zeros(sy**2,1,kern_size,kern_size)\n",
    "        \n",
    "        neg = -1*(1/(sy**2))\n",
    "        pos = 1+neg\n",
    "        \n",
    "        border = int((kern_size-sy)/2)\n",
    "        base = torch.zeros(sy,sy)+neg\n",
    "        cnt=0\n",
    "        \n",
    "        for i in range(sy**2):\n",
    "            base = torch.zeros(sy**2)+neg\n",
    "            base[cnt]=pos\n",
    "            diffms[i,0,border:(kern_size-border),border:(kern_size-border)] = base.reshape([sy,sy])\n",
    "            cnt+=1\n",
    "        return diffms\n",
    "    \n",
    "    \n",
    "    def create_gaus(self, kern_size, sy=9,std=2.15):\n",
    "        n = torch.arange(0,sy)-(sy-1.0)/2.0\n",
    "        sig2 = 2 * std * std\n",
    "        gkern1d = torch.exp(-n ** 2 / sig2)\n",
    "        gkern1d = gkern1d/torch.sum(gkern1d)\n",
    "        #print(gkern1d.shape)\n",
    "        gkern2d = torch.outer(gkern1d, gkern1d)\n",
    "    \n",
    "\n",
    "        # Wrap in zeros, if kern_size > sy\n",
    "        gaussian_filter = torch.zeros(1,1,kern_size,kern_size)\n",
    "        border = int((kern_size-sy)/2)\n",
    "        gaussian_filter[0,0,border:(kern_size-border),border:(kern_size-border)] = gkern2d#(sy,std=std)\n",
    "        #print(gaussian_filter.shape)\n",
    "        return gaussian_filter\n",
    "        \n",
    "    \n",
    "    def fixed_positions(self, tens, mult, sg):\n",
    "        f, _ , h, w = tens.shape\n",
    "        new_filt = torch.zeros(f*mult, 1, sg,sg)\n",
    "        cnt = 0\n",
    "        filt = 0\n",
    "        \n",
    "        for filt in range(f):\n",
    "            for j in range((sg-w)+1):\n",
    "                for i in range((sg-h)+1):\n",
    "                    new_filt[cnt,0,i:i+h,j:j+w] = tens[filt]\n",
    "                    cnt+=1\n",
    "        return new_filt\n",
    "    \n",
    "    def expand_params(self,tens):\n",
    "        return torch.unsqueeze(torch.unsqueeze(tens,2),3)\n",
    "    \n",
    "    def ShLU(self,a, th):\n",
    "        return torch.sign(a)*torch.maximum(abs(a)-th, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimization Parameters\n",
    "DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SCN(9,5,train=True)\n",
    "\n",
    "#net.load_state_dict(torch.load('./MRI_save_29.p'))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {\"params\": net.addp.parameters()},#, \"lr\": 0.0002, \"momentum\": 0.00005},\n",
    "        {\"params\": net.conv.parameters()},#, \"lr\": 0.0003, \"momentum\": 0.0001},\n",
    "        {\"params\": net.wd.parameters()},\n",
    "        {\"params\": net.usd1.parameters()},\n",
    "        {\"params\": net.ud.parameters()},\n",
    "    ],\n",
    "    #lr=0.0001, momentum=0.0001\n",
    "    lr=0.00007, momentum = 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_train = SrGen('./data/train/GT_corr/','./data/train/HR_corr_patches/','./data/train/LR_corr_patches/')\n",
    "\n",
    "temp = sr_train.get_template()\n",
    "temp[\"patch\"]=44\n",
    "temp[\"step\"]=20\n",
    "temp[\"translation_x\"]=10\n",
    "temp[\"translation_y\"]=10\n",
    "temp[\"rotation\"] = 180\n",
    "temp[\"scale\"] = 1\n",
    "sr_train.save_template(temp)\n",
    "\n",
    "sr_train.run(clear=True)\n",
    "\n",
    "sr_train.match_altered(update=True, paths=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sr_class):\n",
    "        self.sr_class = sr_class\n",
    "\n",
    "        # In case I forget to run match_altered before pulling the class\n",
    "        if not sr_class.HR_files:\n",
    "            sr_class.match_altered(update=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sr_class.HR_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Y, X = self.sr_class.load_image_pair(index)\n",
    "        X = torch.unsqueeze(torch.tensor(X, dtype=torch.float32),0)\n",
    "        Y = torch.unsqueeze(torch.tensor(Y, dtype=torch.float32),0)\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 3}\n",
    "\n",
    "training_set = Dataset(sr_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "# Loop over epochs\n",
    "\n",
    "max_epochs = 40\n",
    "save_rate = 5 #save a version of the model every 5 epochs\n",
    "epoch_adjust = 0 #how much to add to the saved files in order to not overwrite\n",
    "save_prefix = \"./MRI_reflect_pad_save_\"\n",
    "\n",
    "mean_loss = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    losses = []\n",
    "\n",
    "    ###### Test running this code where each epoch a new set of random images is made\n",
    "    sr_train.run(clear=True)\n",
    "\n",
    "    training_set = Dataset(sr_train)\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "    ######\n",
    "\n",
    "\n",
    "    # Training\n",
    "    count = 0\n",
    "    for inp, goal in training_generator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(inp,2) # the 2 is the number of iterations in the LISTA network\n",
    "        output = torch.clamp(output, 0, 255)\n",
    "\n",
    "        loss = criterion(output,goal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        #print(f'mini-batch # {count}, mean loss = {sum(losses)/len(losses)}')\n",
    "        count = count+1\n",
    "\n",
    "    if (epoch % save_rate == 0) or epoch == (max_epochs-1):\n",
    "        torch.save(net.state_dict(), f'{save_prefix}{epoch+epoch_adjust}.p')\n",
    "    print(f'\\n\\n epoch {epoch}, loss mean: {sum(losses)/len(losses)}, loss: {min(losses)}-{max(losses)}\\n')\n",
    "    mean_loss.append(sum(losses)/len(losses))\n",
    "\n",
    "    # Give computer time to cool down\n",
    "    time.sleep(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].plot([x for x in range(len(mean_loss[\"CNNIL_1\"]))],mean_loss[\"CNNIL_1\"])\n",
    "axs[0].set_title('Mean Loss for First CNN Block')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing data\n",
    "sr_test = SrGen('./data/test/GT_corr/','./data/test/HR_corr/','./data/test/LR_corr/')\n",
    "\n",
    "\n",
    "temp = sr_test.get_template()\n",
    "temp[\"patch\"]=False #44\n",
    "# temp[\"step\"]=20\n",
    "# temp[\"rotation\"] = 180\n",
    "temp[\"scale\"] = 1\n",
    "temp[\"rotation\"]=180\n",
    "sr_test.save_template(temp)\n",
    "\n",
    "sr_test.run(clear=True)\n",
    "\n",
    "sr_test.match_altered(update=True, paths=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_t = {'batch_size': 1,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2}\n",
    "\n",
    "testing_set = Dataset(sr_test, axs = 'hw')\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **params_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matched images\n",
    "im_hr, im_lr = sr_test.match_altered(update = True, paths=True)\n",
    "\n",
    "save_pred = False # Whether to save the images created by the network during testing\n",
    "save_dir = \"./\"\n",
    "if save_pred:\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in im_hr: #range(len(im_hr)):\n",
    "\n",
    "        # Load in image information\n",
    "        im_h, im_l = sr_test.load_image_pair(i)\n",
    "\n",
    "        # Take low resolution and upscale using bicubic interpolation\n",
    "        # (which has already been done due to the image generation process)\n",
    "        # Thus im_l is the bicubic interpolation to compare to...\n",
    "\n",
    "        # Use SR model on low resolution image\n",
    "        im_h_sr = net(torch.unsqueeze(torch.unsqueeze(torch.tensor(im_l, dtype=torch.float32),0),0),2)\n",
    "\n",
    "        # Calculate PSNR for bicubic\n",
    "        im_l = np.rint( np.clip(im_l, 0, 255))\n",
    "        im_h = np.rint( np.clip(im_h, 0, 255))\n",
    "        diff = im_l - im_h\n",
    "        rmse = np.sqrt((diff**2).mean())\n",
    "        psnr = 20*np.log10(255.0/rmse)\n",
    "\n",
    "        print(f'bicubic evaluation for {i}: rms={rmse}, psnr={psnr}')\n",
    "\n",
    "        # Calculate PSNR for SR\n",
    "        im_h_sr = np.rint( np.clip(im_h_sr, 0, 255))\n",
    "        im_h = np.rint( np.clip(im_h, 0, 255))\n",
    "        diff = im_h_sr - im_h\n",
    "        rmse = np.sqrt((diff**2).mean())\n",
    "        psnr = 20*np.log10(255.0/rmse)\n",
    "        print(f'SR evaluation for {i}: rms={rmse}, psnr={psnr}')\n",
    "\n",
    "        if save_pred:\n",
    "            img_name = os.path.splitext(os.path.basename(i))[0]\n",
    "            Image.fromarray(np.rint(im_h_sr).astype(np.uint8)).save(f\"{save_dir}/{img_name}_SR.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, plot a histogram of how well the SR image performed compared to the Bicubic comparison\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].hist([float(x) for x in comp['psnr']], bins=10)\n",
    "axs[0].set_title('PSNR: SR - BiC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing data for both axes\n",
    "sr = SrGen('../data/CNNIL_nifti/Raw_test/','../data/CNNIL_nifti/Full_test/','../data/CNNIL_nifti/LR_Full_test/')\n",
    "\n",
    "temp = sr.get_template()\n",
    "temp['out_type'] = 'nii'\n",
    "temp['resolution'] = [2,2,2]\n",
    "temp['translation'] = [0, 0, 0]\n",
    "temp['rotation'] = [0, 0, 0]\n",
    "temp['keep_blank'] = False\n",
    "temp['same_size'] = False\n",
    "\n",
    "sr.set_template(temp)\n",
    "\n",
    "#sr.run(clear=True, save=True)\n",
    "sr.match_altered(update=True, paths=False, sort=False)\n",
    "\n",
    "\n",
    "params_t = {'batch_size': 1,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2}\n",
    "\n",
    "full_img_generator = Dataset(sr, axs = 'hw'### Use the models for SR of MRI images and calculate PSNR\n",
    "# Load trained models:\n",
    "net_1.load_state_dict(torch.load('CNNIL_save_network1_39.p'))\n",
    "net_2.load_state_dict(torch.load('CNNIL_save_network2_39.p'))\n",
    "\n",
    "# Where or not to save the output SR images, if None then don't save any:\n",
    "save_pre = './SR_images'\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    comp={'psnr' : [], 'rmse' : []}\n",
    "    for idx, [im_l, im_h] in enumerate(full_img_generator):\n",
    "\n",
    "        output_1, output_2 = net_1(torch.transpose(im_l,0,1))\n",
    "        output_1, output_2 = net_2(torch.transpose(output_2,0,3))\n",
    "        output_2 = torch.transpose(torch.squeeze(output_2,1),2,0)\n",
    "\n",
    "        # Upscale im_l to the same size as im_h\n",
    "        im_l = torch.tensor(resize(im_l, im_h.shape, order=1, mode = 'symmetric'))\n",
    "\n",
    "        # Calculate PSNR for bicubic\n",
    "        diff = im_l - im_h\n",
    "        rmse_b = np.sqrt((diff**2).mean())\n",
    "        psnr_b = 20*np.log10(im_h.max()/rmse_b)\n",
    "\n",
    "\n",
    "        # Calculate PSNR for SR\n",
    "        diff = output_2 - im_h\n",
    "        rmse_s = np.sqrt((diff**2).mean())\n",
    "        psnr_s = 20*np.log10(im_h.max()/rmse_s)\n",
    "\n",
    "        comp['psnr'].append(psnr_s-psnr_b)\n",
    "        comp['rmse'].append(rmse_s-rmse_b)\n",
    "\n",
    "        if save_pre:\n",
    "            # Save the resulting images as .nii files\n",
    "            os.makedirs(save_pre,exist_ok=True)\n",
    "            sr.save_image(f'{save_pre}/{sr.LR_files[idx].split(\"/\")[-1]}', output_2.numpy())\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].hist([float(x) for x in comp['psnr']], bins=10)\n",
    "axs[0].set_title('PSNR: SR - BiC')\n",
    "axs[1].hist([float(x) for x in comp['rmse']], bins=10)\n",
    "axs[1].set_title('RMSE: SR - BiC')\n",
    "### Compare Slices from SR and HR image\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(torch.squeeze(output_2[40,:,:],0))\n",
    "axs[0].set_title('Super Resolution')\n",
    "axs[1].imshow(sr.load_image(sr.HR_files[-1])[40,:,:])\n",
    "axs[1].set_title('Truth')\n",
    "## Conclusion\n",
    "\n",
    "There we have it! A nice version of the pipeline discussed using Pytorch!\n",
    "\n",
    "Potential directions for future development:\n",
    "- Determine how well the model works with different MRI collection parameters\n",
    "- Train it on other medical image types aside from MRI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
