{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d40dd99-13f0-4e59-b6d4-1552ba23a5a7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec8fd45-2e9e-48e0-ac0f-85598c17f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle as pickle\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301893b2-bbc4-404c-a560-9888e735c7c9",
   "metadata": {},
   "source": [
    "## Model trained on BSD100 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5840c7f-b842-4acf-8160-47c5f056c9ad",
   "metadata": {},
   "source": [
    "If you want to load the trained model set ?? to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52efc78-5ff5-47e8-991e-f662fea1c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN(nn.Module):\n",
    "    def __init__(self,sy,sg, model_file=False, train=True):\n",
    "        super().__init__()\n",
    "        #Initialize layer weights:\n",
    "        C = 5\n",
    "        L = 5\n",
    "        \n",
    "        Dx = torch.normal(0,1, size = (25,128))\n",
    "        Dy = torch.normal(0,1,size = (100,128))\n",
    "        I = torch.eye(128)\n",
    "        \n",
    "        self.conv = nn.Conv2d(1,100,9, bias=False, stride=1, padding=0)\n",
    "        self.mean2 = nn.Conv2d(1,1,13, bias=False, stride=1, padding=0)\n",
    "        self.diffms = nn.Conv2d(1,25, 9, bias=False, stride=1, padding=0)\n",
    "        \n",
    "        self.wd = nn.Conv2d(100,128, 1,bias=False,stride=1)\n",
    "        self.usd1 = nn.Conv2d(128, 128, 1, bias=False, stride=1)\n",
    "        self.ud = nn.Conv2d(128,25, 1, bias=False, stride=1)\n",
    "        self.addp = nn.Conv2d(25,1,1,bias=False, stride=1)#, padding=4)\n",
    "\n",
    "        if train:\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13),requires_grad=False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T))\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)))\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx))\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,25,1,1)*0.04)#, requires_grad=False)\n",
    "        else:\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13),requires_grad=False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T),requires_grad=False)\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)),requires_grad=False)\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx),requires_grad=False)\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,25,1,1)*0.04,requires_grad=False)#, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x, k, sy=9,sg=5):\n",
    "        print(f'x = {x.shape}')\n",
    "        print({x.max()})\n",
    "        im_mean = self.mean2(x)\n",
    "        diffms = self.diffms(x)\n",
    "        print(f'x max = {x.max()}')\n",
    "        print(f'x min = {x.min()}')\n",
    "        \n",
    "        \n",
    "        #pad data out\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        x = x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True)\n",
    "        \n",
    "        x = self.wd(x)\n",
    "        z = self.ShLU(x,1)        \n",
    "        \n",
    "        #Go through LISTA\n",
    "        for i in range(k):\n",
    "            z = self.ShLU(self.usd1(z)+x,1)\n",
    "        x = self.ud(z)\n",
    "\n",
    "        x = (x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True))*torch.linalg.vector_norm(diffms, ord=2, dim=1, keepdim=True)*1.1\n",
    "        x = self.reassemble2(x,im_mean,sg)\n",
    "        x = self.addp(x)\n",
    "\n",
    "        x = x+im_mean\n",
    "        print(f'final addition max = {x.max()}')\n",
    "        print(f'final addition min = {x.min()}')\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def reassemble(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        cnt = 0\n",
    "        \n",
    "        img_stack=torch.zeros(s,c,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    #print(x[q,filt,jj:(jj+h), ii:(ii+w)].shape)\n",
    "                    img_stack[q,0,:,:] = img_stack[q,0,:,:]+x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack+img\n",
    "    \n",
    "    def reassemble2(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        cnt = 0\n",
    "        \n",
    "        img_stack=torch.zeros(s,25,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    img_stack[q,filt,:,:] = x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack\n",
    "    \n",
    "    \n",
    "    def create_diffms(self, kern_size, sy=5):\n",
    "        diffms = torch.zeros(sy**2,1,kern_size,kern_size)\n",
    "        \n",
    "        neg = -1*(1/(sy**2))\n",
    "        pos = 1+neg\n",
    "        \n",
    "        border = int((kern_size-sy)/2)\n",
    "        base = torch.zeros(sy,sy)+neg\n",
    "        cnt=0\n",
    "        \n",
    "        for i in range(sy**2):\n",
    "            base = torch.zeros(sy**2)+neg\n",
    "            base[cnt]=pos\n",
    "            diffms[i,0,border:(kern_size-border),border:(kern_size-border)] = base.reshape([sy,sy])\n",
    "            cnt+=1\n",
    "        return diffms\n",
    "    \n",
    "    \n",
    "    def create_gaus(self, kern_size, sy=9,std=2.15):\n",
    "        n = torch.arange(0,sy)-(sy-1.0)/2.0\n",
    "        sig2 = 2 * std * std\n",
    "        gkern1d = torch.exp(-n ** 2 / sig2)\n",
    "        gkern1d = gkern1d/torch.sum(gkern1d)\n",
    "        #print(gkern1d.shape)\n",
    "        gkern2d = torch.outer(gkern1d, gkern1d)\n",
    "    \n",
    "\n",
    "        # Wrap in zeros, if kern_size > sy\n",
    "        gaussian_filter = torch.zeros(1,1,kern_size,kern_size)\n",
    "        border = int((kern_size-sy)/2)\n",
    "        gaussian_filter[0,0,border:(kern_size-border),border:(kern_size-border)] = gkern2d#(sy,std=std)\n",
    "        #print(gaussian_filter.shape)\n",
    "        return gaussian_filter\n",
    "    \n",
    "    def fixed_positions(self, tens, mult, sg):\n",
    "        f, _ , h, w = tens.shape\n",
    "        new_filt = torch.zeros(f*mult, 1, sg,sg)\n",
    "        #new_filt = torch.zeros(1,f*mult,sg,sg)\n",
    "        cnt = 0\n",
    "        filt = 0\n",
    "        \n",
    "        for filt in range(f):\n",
    "            for j in range((sg-w)+1):\n",
    "                for i in range((sg-h)+1):\n",
    "                    new_filt[cnt,0,i:i+h,j:j+w] = tens[filt]\n",
    "                    #new_filt[0,cnt,i:i+h,j:j+w] = tens[filt]\n",
    "                    cnt+=1\n",
    "        return new_filt\n",
    "    \n",
    "    \n",
    "    \n",
    "    def expand_params(self,tens):\n",
    "        return torch.unsqueeze(torch.unsqueeze(tens,2),3)\n",
    "    \n",
    "    def ShLU(self,a, th):\n",
    "        return torch.sign(a)*torch.maximum(abs(a)-th, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc31ab-0d5e-41d3-b8e2-0704c5755fc2",
   "metadata": {},
   "source": [
    "## Instantiate network and load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ff7b1d-dd63-4680-af18-8841063265a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SCN(9,5,train=False)\n",
    "net.load_state_dict(torch.load('/home/ross/Documents/CODE/sparse/SCN_BSD_final.p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8c230-fda2-4779-b055-849eab4e1a81",
   "metadata": {},
   "source": [
    "## Model Trained on MRI data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2da80-949d-4823-9542-7ff5beb75cf7",
   "metadata": {},
   "source": [
    "If you want to load the traind model set ?? to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6706848a-d4e0-4321-a66c-fecb6e1169df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN(nn.Module):\n",
    "    def __init__(self,sy,sg, model_file=False, train=True):\n",
    "        super().__init__()\n",
    "        #Initialize layer weights:\n",
    "        C = 5\n",
    "        L = 5\n",
    "        \n",
    "        Dx = torch.normal(0,1, size = (25,128))\n",
    "        Dy = torch.normal(0,1,size = (100,128))\n",
    "        I = torch.eye(128)\n",
    "        #self.conv = nn.Conv2d(1,4,sg, bias=False, stride=1, padding=0)\n",
    "        #self.conv = nn.Conv2d(1,6,sg+1, bias=False, stride=1, padding=0)\n",
    "        self.conv = nn.Conv2d(1,100,9,bias=False, stride=1,padding=0)\n",
    "        self.mean2 = nn.Conv2d(1,1,13, bias=False, stride=1, padding=0)\n",
    "        self.diffms = nn.Conv2d(1,25, 9, bias=False, stride=1, padding=0)\n",
    "        \n",
    "        self.wd = nn.Conv2d(100,128, 1,bias=False,stride=1)\n",
    "        self.usd1 = nn.Conv2d(128, 128, 1, bias=False, stride=1)\n",
    "        self.ud = nn.Conv2d(128,25, 1, bias=False, stride=1)\n",
    "        #self.addp = nn.Conv2d(25,1,1,bias=False, stride=1)#, padding=4)\n",
    "        self.addp = nn.Conv2d(16,1,1,bias=False, stride=1)#, padding=4)\n",
    "        \n",
    "        if train:\n",
    "            #self.conv.weight = torch.nn.Parameter(self.create_haar(sg,4))\n",
    "            #self.conv.weight = torch.nn.Parameter(self.create_haar(6,6),requires_grad=True)\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13),requires_grad=False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T), requires_grad=True)\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)), requires_grad=True)\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx), requires_grad=True)\n",
    "            #self.addp.weight = torch.nn.Parameter(torch.ones(1,25,1,1)*0.04)#, requires_grad=False)\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,16,1,1)*0.06, requires_grad=True)\n",
    "\n",
    "        else:\n",
    "            #self.conv.weight = torch.nn.Parameter(self.create_haar(sg,4),requires_grad=False)\n",
    "            #self.conv.weight = torch.nn.Parameter(self.create_haar(6,6),requires_grad=False)\n",
    "            self.conv.weight = torch.nn.Parameter(torch.ones(100,1,9,9),requires_grad=False)\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13),requires_grad=False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T),requires_grad=False)\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)),requires_grad=False)\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx),requires_grad=False)\n",
    "            #self.addp.weight = torch.nn.Parameter(torch.ones(1,25,1,1)*0.04,requires_grad=False)\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,16,1,1)*0.06,requires_grad=False)\n",
    "\n",
    "            #self.upstep = nn.Conv2d(1,100,sy,bias=False, stride=1, padding=0)\n",
    "\n",
    "        \n",
    "    def forward(self, x, k, sy=9,sg=5):\n",
    "        im_mean = self.mean2(x)\n",
    "        diffms = self.diffms(x)\n",
    "\n",
    "        cnt=0\n",
    "        n, c, h, w = x.shape\n",
    "        y = torch.zeros(n,100,h-8,w-8)\n",
    "        x = self.conv(x)\n",
    "        x = x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True)\n",
    "        \n",
    "        x = self.wd(x)\n",
    "        z = self.ShLU(x,1)\n",
    "        \n",
    "        #Go through LISTA\n",
    "        for i in range(k):\n",
    "            z = self.ShLU(self.usd1(z)+x,1)\n",
    "\n",
    "        x = self.ud(z)\n",
    "        x = (x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True))*torch.linalg.vector_norm(diffms, ord=2, dim=1, keepdim=True)*1.1\n",
    "        x = self.reassemble2(x,im_mean,4)\n",
    "        x = self.addp(x)\n",
    "        print(f'x.reassemble.max = {x.max()}')\n",
    "        x = x+im_mean\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def reassemble(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        cnt = 0\n",
    "        img_stack=torch.zeros(s,c,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    img_stack[q,0,:,:] = img_stack[q,0,:,:]+x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack+img\n",
    "    \n",
    "    def reassemble2(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        cnt = 0\n",
    "        \n",
    "        \n",
    "#        img_stack=torch.zeros(s,25,h,w)\n",
    "        img_stack=torch.zeros(s,16,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    img_stack[q,filt,:,:] = x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack\n",
    "    \n",
    "    \n",
    "    def create_diffms(self, kern_size, sy=5):\n",
    "        diffms = torch.zeros(sy**2,1,kern_size,kern_size)\n",
    "        \n",
    "        neg = -1*(1/(sy**2))\n",
    "        pos = 1+neg\n",
    "        \n",
    "        border = int((kern_size-sy)/2)\n",
    "        base = torch.zeros(sy,sy)+neg\n",
    "        cnt=0\n",
    "        \n",
    "        for i in range(sy**2):\n",
    "            base = torch.zeros(sy**2)+neg\n",
    "            base[cnt]=pos\n",
    "            diffms[i,0,border:(kern_size-border),border:(kern_size-border)] = base.reshape([sy,sy])\n",
    "            cnt+=1\n",
    "        return diffms\n",
    "    \n",
    "    \n",
    "    def create_gaus(self, kern_size, sy=9,std=2.15):\n",
    "        n = torch.arange(0,sy)-(sy-1.0)/2.0\n",
    "        sig2 = 2 * std * std\n",
    "        gkern1d = torch.exp(-n ** 2 / sig2)\n",
    "        gkern1d = gkern1d/torch.sum(gkern1d)\n",
    "        #print(gkern1d.shape)\n",
    "        gkern2d = torch.outer(gkern1d, gkern1d)\n",
    "    \n",
    "\n",
    "        # Wrap in zeros, if kern_size > sy\n",
    "        gaussian_filter = torch.zeros(1,1,kern_size,kern_size)\n",
    "        border = int((kern_size-sy)/2)\n",
    "        gaussian_filter[0,0,border:(kern_size-border),border:(kern_size-border)] = gkern2d#(sy,std=std)\n",
    "        #print(gaussian_filter.shape)\n",
    "        return gaussian_filter\n",
    "    \n",
    "    def create_haar(self, kern_size, num):\n",
    "        haar = torch.zeros(num,1,kern_size,kern_size)\n",
    "        haar[0,0,:,:] = torch.tensor([[-1,-1,-1,1,1,1],\n",
    "                                      [-1,-1,-1,1,1,1],\n",
    "                                      [-1,-1,-1,1,1,1],\n",
    "                                      [-1,-1,-1,1,1,1],\n",
    "                                     [-1,-1,-1,1,1,1],\n",
    "                                     [-1,-1,-1,1,1,1]])\n",
    "        \n",
    "        haar[1,0,:,:] = torch.tensor([[-1,-1,-1,-1,-1,-1],\n",
    "                                      [-1,-1,-1,-1,-1,-1],\n",
    "                                      [-1,-1,-1,-1,-1,-1],\n",
    "                                      [1,1,1,1,1,1],\n",
    "                                      [1,1,1,1,1,1],\n",
    "                                     [1,1,1,1,1,1]])\n",
    "        \n",
    "        haar[2,0,:,:] = torch.tensor([[1,1,-1,-1,1,1],\n",
    "                                      [1,1,-1,-1,1,1],\n",
    "                                      [1,1,-1,-1,1,1],\n",
    "                                      [1,1,-1,-1,1,1],\n",
    "                                     [1,1,-1,-1,1,1],\n",
    "                                     [1,1,-1,-1,1,1]])\n",
    "        \n",
    "        haar[3,0,:,:] = torch.tensor([[1,1,1,1,1,1],\n",
    "                                      [1,1,1,1,1,1],\n",
    "                                      [-1,-1,-1,-1,-1,-1],\n",
    "                                      [-1,-1,-1,-1,-1,-1],\n",
    "                                     [1,1,1,1,1,1],\n",
    "                                     [1,1,1,1,1,1]])\n",
    "        \n",
    "        haar[4,0,:,:] = torch.tensor([[1,1,1,-1,-1,-1],\n",
    "                                      [1,1,1,-1,-1,-1],\n",
    "                                      [1,1,1,-1,-1,-1],\n",
    "                                      [-1,-1,-1,1,1,1],\n",
    "                                     [-1,-1,-1,1,1,1],\n",
    "                                     [-1,-1,-1,1,1,1]])\n",
    "        haar[5,0,:,:] = torch.tensor([[1,1,1,1,1,1],\n",
    "                                      [1,1,1,1,1,1],\n",
    "                                      [1,1,-1,-1,1,1],\n",
    "                                      [1,1,-1,-1,1,1],\n",
    "                                      [1,1,1,1,1,1],\n",
    "                                     [1,1,1,1,1,1]])\n",
    "        return haar\n",
    "        \n",
    "    \n",
    "    def fixed_positions(self, tens, mult, sg):\n",
    "        f, _ , h, w = tens.shape\n",
    "        new_filt = torch.zeros(f*mult, 1, sg,sg)\n",
    "        cnt = 0\n",
    "        filt = 0\n",
    "        \n",
    "        for filt in range(f):\n",
    "            for j in range((sg-w)+1):\n",
    "                for i in range((sg-h)+1):\n",
    "                    new_filt[cnt,0,i:i+h,j:j+w] = tens[filt]\n",
    "                    cnt+=1\n",
    "        return new_filt\n",
    "    \n",
    "    def expand_params(self,tens):\n",
    "        return torch.unsqueeze(torch.unsqueeze(tens,2),3)\n",
    "    \n",
    "    def ShLU(self,a, th):\n",
    "        return torch.sign(a)*torch.maximum(abs(a)-th, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "219d56c9-7232-4617-95b8-00d7f49706b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SCN(9,5,train=False)\n",
    "net.load_state_dict(torch.load('/home/ross/Documents/CODE/sparse/sparse_SR/nn-code/MRI_run_SGD_v100_57.p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786adfc-9712-4087-8d57-9a175d07d605",
   "metadata": {},
   "source": [
    "## Load Dataset Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c025ec-692a-4eeb-99e8-f9d743cbdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  #'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, in_dir, inputs, tar_dir, targets):\n",
    "        #'Initialization'\n",
    "        self.list_input = inputs\n",
    "        self.list_target = targets\n",
    "        self.in_dir = in_dir\n",
    "        self.tar_dir = tar_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.list_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        # Select sample\n",
    "        inp = self.list_input[index]\n",
    "        target = self.list_target[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        #X = torch.load(self.in_dir + inp)\n",
    "        #Y = torch.load(self.tar_dir + target)\n",
    "        im_l = np.array(Image.open(self.in_dir + inp))[:,:,:3]\n",
    "        im_gt = np.array(Image.open(self.tar_dir + target))[:,:,:3]\n",
    "        \n",
    "        s=2\n",
    "        \n",
    "        im_l = im_l/255.0\n",
    "        if len(im_l.shape)==3 and im_l.shape[2]==3:\n",
    "            im_l_ycbcr = rgb2ycbcr(im_l)\n",
    "        else:\n",
    "            im_l_ycbcr = np.zeros([im_l.shape[0], im_l.shape[1], 3])\n",
    "            im_l_ycbcr[:, :, 0] = im_l\n",
    "            im_l_ycbcr[:, :, 1] = im_l\n",
    "            im_l_ycbcr[:, :, 2] = im_l\n",
    "\n",
    "\n",
    "        #im_l_y is the luminance values of the image\n",
    "        im_l_y = im_l_ycbcr[:, :, 0]*255 #[16 235]\n",
    "        #im_l_y = imresize(im_l_y,s)\n",
    "        im_l_y = ExtendBorder(im_l_y,6)\n",
    "\n",
    "\n",
    "        if len(im_gt.shape)==3:\n",
    "            im_gt_ycbcr = rgb2ycbcr(im_gt/255.0)*255.0\n",
    "            im_gt_y = im_gt_ycbcr[:, :, 0]\n",
    "        else:\n",
    "            im_gt_y = im_gt\n",
    "        \n",
    "        \n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        X = torch.unsqueeze(torch.tensor(im_l_y, dtype=torch.float32),0)\n",
    "        #X = convert_tensor(im_l_y)\n",
    "        Y = torch.unsqueeze(torch.tensor(im_gt_y, dtype=torch.float32),0)\n",
    "        #Y = convert_tensor(im_gt_y)\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5802f7-2b39-464f-bdaf-c94eb0bf37da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "495b2431-581a-45bf-84bf-2548457a97f3",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829dd5db-3d76-4988-8bea-f27a014ab10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(im_l, s, nn=True):\n",
    "    \"\"\"\n",
    "    % im_l: LR image, float np array in [0, 255]\n",
    "    % im_h: HR image, float np array in [0, 255]\n",
    "    \"\"\"\n",
    "    im_l = im_l/255.0\n",
    "    if len(im_l.shape)==3 and im_l.shape[2]==3:\n",
    "        im_l_ycbcr = rgb2ycbcr(im_l)\n",
    "    else:\n",
    "        im_l_ycbcr = np.zeros([im_l.shape[0], im_l.shape[1], 3])\n",
    "        im_l_ycbcr[:, :, 0] = im_l\n",
    "        im_l_ycbcr[:, :, 1] = im_l\n",
    "        im_l_ycbcr[:, :, 2] = im_l\n",
    "    \n",
    "\n",
    "    #im_l_y is the luminance values of the image\n",
    "    im_l_y = im_l_ycbcr[:, :, 0]*255 #[16 235]\n",
    "    if nn==True:\n",
    "        im_l_y = imresize(im_l_y,s)\n",
    "        print(im_l_y.max())\n",
    "        print(im_l_y.min())\n",
    "        im_l_y = ExtendBorder(im_l_y,6)\n",
    "        im_l_y = torch.unsqueeze(torch.unsqueeze(torch.tensor(im_l_y, dtype=torch.float32),0),0)\n",
    "        im_h_y = net(im_l_y,2)\n",
    "        #im_h_y = self.upscale_alg(im_l_y, s)\n",
    "        im_h_y = torch.squeeze(torch.squeeze(im_h_y,0),0)\n",
    "        im_h_y = im_h_y.detach().numpy()\n",
    "    else:\n",
    "        im_h_y = imresize(im_l_y, s)\n",
    "\n",
    "    # recover color\n",
    "    if len(im_l.shape)==3:\n",
    "        im_ycbcr = imresize(im_l_ycbcr, s)\n",
    "        im_ycbcr[:, :, 0] = im_h_y/255.0; #[16/255 235/255]\n",
    "        im_h = ycbcr2rgb(im_ycbcr)*255.0\n",
    "    else:\n",
    "        im_h = im_h_y\n",
    "\n",
    "    im_h = np.clip(im_h, 0, 255)\n",
    "    im_h_y = np.clip(im_h_y, 0, 255)\n",
    "    return im_h,im_h_y\n",
    "\n",
    "def ExtendBorder(im, offset):\n",
    "    sz = im.shape\n",
    "    assert(len(sz)==2)\n",
    "\n",
    "    im2 = np.zeros([sz[0]+offset*2, sz[1]+offset*2])\n",
    "    im2[ offset:-offset, offset:-offset ] = im\n",
    "    im2[ offset:-offset, 0:offset ] = im[:, offset:0:-1]\n",
    "    im2[ offset:-offset, -offset: ] = im[:, -2:-(offset+2):-1]\n",
    "    im2[ 0:offset, :] = im2[2*offset:offset:-1, :]\n",
    "    im2[ -offset:, :] = im2[-(offset+2):-(2*offset+2):-1, :]\n",
    "\n",
    "    return im2\n",
    "\n",
    "def imresize(im_l, s):\n",
    "    if s<1:\n",
    "        im_l = cv2.GaussianBlur(im_l, (7,7), s)\n",
    "    im_h = cv2.resize(im_l, (0,0), fx=s, fy=s, interpolation=cv2.INTER_CUBIC)\n",
    "    return im_h\n",
    "\n",
    "def rgb2ycbcr(im_rgb):\n",
    "    im_rgb = im_rgb.astype(np.float32)\n",
    "    im_ycrcb = cv2.cvtColor(im_rgb, cv2.COLOR_RGB2YCR_CB) #converts the RBG colors into YCbCr colorspace\n",
    "    im_ycbcr = im_ycrcb[:,:,(0,2,1)].astype(np.float32)\n",
    "    im_ycbcr[:,:,0] = (im_ycbcr[:,:,0]*(235-16)+16)/255.0 #to [16/255, 235/255]\n",
    "    im_ycbcr[:,:,1:] = (im_ycbcr[:,:,1:]*(240-16)+16)/255.0 #to [16/255, 240/255]\n",
    "    return im_ycbcr\n",
    "\n",
    "def ycbcr2rgb(im_ycbcr):\n",
    "    im_ycbcr = im_ycbcr.astype(np.float32)\n",
    "    im_ycbcr[:,:,0] = (im_ycbcr[:,:,0]*255.0-16)/(235-16) #to [0, 1]\n",
    "    im_ycbcr[:,:,1:] = (im_ycbcr[:,:,1:]*255.0-16)/(240-16) #to [0, 1]\n",
    "    im_ycrcb = im_ycbcr[:,:,(0,2,1)].astype(np.float32)\n",
    "    im_rgb = cv2.cvtColor(im_ycrcb, cv2.COLOR_YCR_CB2RGB)\n",
    "    return im_rgb\n",
    "\n",
    "def Shave(im, border):\n",
    "    if isinstance(border, int):\n",
    "        border=[border, border]\n",
    "    im = im[border[0]:-border[0], border[1]:-border[1], ...]\n",
    "    return im\n",
    "\n",
    "def modcrop(im, modulo):\n",
    "    sz = im.shape\n",
    "    h = int(sz[0]/modulo*modulo)\n",
    "    w = int(sz[1]/modulo*modulo)\n",
    "    ims = im[0:h, 0:w, ...]\n",
    "    return ims\n",
    "\n",
    "def evalimg(im_h_y, im_gt, shav=0):\n",
    "    if len(im_gt.shape)==3:\n",
    "        im_gt_ycbcr = rgb2ycbcr(im_gt/255.0)*255.0\n",
    "        im_gt_y = im_gt_ycbcr[:, :, 0]\n",
    "    else:\n",
    "        im_gt_y = im_gt\n",
    "\n",
    "    im_h_y_uint8 = np.rint( np.clip(im_h_y, 0, 255))\n",
    "    im_gt_y_uint8 = np.rint( np.clip(im_gt_y, 0, 255))\n",
    "    diff = im_h_y_uint8 - im_gt_y_uint8\n",
    "    #diff = im_h_y - im_gt_y\n",
    "    if shav>0:\n",
    "        diff = Shave(diff, [shav, shav])\n",
    "    res = {}\n",
    "    res['rmse'] = np.sqrt((diff**2).mean())\n",
    "    res['psnr'] = 20*np.log10(255.0/res['rmse'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1d3c9-0ab8-4b56-ae71-508ec17209fe",
   "metadata": {},
   "source": [
    "## Set Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f80aa-03dd-4eeb-a433-eebde621dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SCN(9,5,train=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {\"params\": net.addp.parameters()},#, \"lr\": 0.0002, \"momentum\": 0.00005},\n",
    "        {\"params\": net.conv.parameters()},#, \"lr\": 0.0003, \"momentum\": 0.0001},\n",
    "        {\"params\": net.wd.parameters()},\n",
    "        {\"params\": net.usd1.parameters()},\n",
    "        {\"params\": net.ud.parameters()},\n",
    "    ],\n",
    "    lr=0.00007, momentum = 0.0001\n",
    ")\n",
    "\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b14b6d-bf3a-4c02-aea3-e481a4c48cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = '/home/ross/Documents/CODE/sparse/sparse_SR/nn-code/data'\n",
    "\n",
    "training_set = Dataset(f'{pat}/shuff_nii_sub_LR_patches/',os.listdir(f'{pat}/shuff_nii_sub_LR_patches'),f'{pat}/shuff_nii_sub_HR_patches/', os.listdir(f'{pat}/shuff_nii_sub_LR_patches'))\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc935f-2fef-415f-b267-05b8ed455ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "UP_SCALE=2\n",
    "SHAVE=1 #set 1 to be consistant with SRCNN\n",
    "\n",
    "# load inputs\n",
    "im_gt = []\n",
    "im_l = []\n",
    "\n",
    "max_epochs = 3\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Loop over epochs\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    losses=[]\n",
    "    losses_per = []\n",
    "    # Training\n",
    "    count=0\n",
    "    for inp, goal in training_generator:\n",
    "        # Transfer to GPU\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        #print(inp.type())\n",
    "        output = net(inp,2)\n",
    "        output = torch.clamp(output, 0, 255)\n",
    "        \n",
    "        #print(f'goal max = {goal.max()}')\n",
    "        loss = criterion(output,goal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        print(f'mini-batch # {count}, mean loss = {sum(losses)/len(losses)}')\n",
    "        count= count+1\n",
    "    \n",
    "    torch.save(net.state_dict(), f'/home/ross/Documents/CODE/sparse/sparse_SR/nn-code/MRI_run_SGD_v100_{epoch+69}.p')\n",
    "    print(f'\\n\\n epoch {epoch}, loss mean: {sum(losses)/len(losses)}, loss: {min(losses)}-{max(losses)}\\n')\n",
    "    #print(net.conv.weight)\n",
    "    time.sleep(160)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b2eb2-bce0-4e30-a9a2-4125ee0ab3e5",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33c5a90d-65a8-4a2c-8402-c787277ecae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.4183\n",
      "15.002569\n",
      "x.reassemble.max = 51.64139938354492\n",
      "138_2-0-0-0.png\n",
      "138_2-0-0-0.png\n",
      "evaluation against 138_2-0-0-0.png, rms=2.7250, psnr=39.4236\n",
      "bicubic evaluation against 138_2-0-0-0.png, rms=3.0962, psnr=38.3143\n",
      "167.75838\n",
      "14.892883\n",
      "x.reassemble.max = 56.16862106323242\n",
      "109_2-0-0-0.png\n",
      "109_2-0-0-0.png\n",
      "evaluation against 109_2-0-0-0.png, rms=3.5079, psnr=37.2298\n",
      "bicubic evaluation against 109_2-0-0-0.png, rms=3.9509, psnr=36.1970\n",
      "167.88416\n",
      "14.963648\n",
      "x.reassemble.max = 51.8637580871582\n",
      "132_2-0-0-0.png\n",
      "132_2-0-0-0.png\n",
      "evaluation against 132_2-0-0-0.png, rms=3.5806, psnr=37.0517\n",
      "bicubic evaluation against 132_2-0-0-0.png, rms=3.9567, psnr=36.1841\n",
      "194.13962\n",
      "14.185234\n",
      "x.reassemble.max = 44.68369674682617\n",
      "152_3-2-0-14.png\n",
      "152_3-2-0-14.png\n",
      "evaluation against 152_3-2-0-14.png, rms=4.5912, psnr=34.8923\n",
      "bicubic evaluation against 152_3-2-0-14.png, rms=5.4251, psnr=33.4427\n",
      "189.92552\n",
      "14.75666\n",
      "x.reassemble.max = 62.28560256958008\n",
      "176_2-0-0-0.png\n",
      "176_2-0-0-0.png\n",
      "evaluation against 176_2-0-0-0.png, rms=3.8096, psnr=36.5133\n",
      "bicubic evaluation against 176_2-0-0-0.png, rms=4.5932, psnr=34.8884\n",
      "mean SCN PSNR: 37.02212485392981\n",
      "mean bicubic PSNR: 35.80532162531388\n"
     ]
    }
   ],
   "source": [
    "UP_SCALE=2\n",
    "SHAVE=1 #set 1 to be consistant with SRCNN\n",
    "save_SR = False\n",
    "\n",
    "# load inputs\n",
    "im_gt = []\n",
    "im_l = []\n",
    "\n",
    "lr_dir = '/home/ross/Documents/CODE/sparse/sparse_SR/test_images_LR'\n",
    "gt_dir = '/home/ross/Documents/CODE/sparse/sparse_SR/test_images_HR'\n",
    "out_dir = '/home/ross/Documents/CODE/sparse/sparse_SR/nn-code/data/outputs_sag'\n",
    "\n",
    "\n",
    "IMAGE_FILE=os.listdir(lr_dir)#'./example_test/data/slena.bmp'\n",
    "IMAGE_GT_FILE=os.listdir(gt_dir)#'./example_test/data/mlena.bmp'\n",
    "\n",
    "#files_gt = IMAGE_GT_FILE\n",
    "for f in IMAGE_GT_FILE:\n",
    "    #print 'loading', f\n",
    "    im = np.array(Image.open(f'{gt_dir}/{f}'))[:,:,:3]\n",
    "    im = modcrop(im, UP_SCALE).astype(np.float32)\n",
    "    im_gt += [im]\n",
    "\n",
    "for f in IMAGE_FILE:\n",
    "    #assert(len(im_gt)==1)\n",
    "    #im_l += [np.array(Image.open(IMAGE_FILE)).astype(np.float32)]\n",
    "    im_l += [np.array(Image.open(f'{lr_dir}/{f}')).astype(np.float32)[:,:,:3]]\n",
    "    \n",
    "res_all = []\n",
    "res_all_b=[]\n",
    "for i in range(len(im_l)):\n",
    "    im_h, im_h_y=upscale(im_l[i], UP_SCALE)\n",
    "    \n",
    "    # evaluation\n",
    "    if SHAVE==1:\n",
    "        shave = round(UP_SCALE)\n",
    "    else:\n",
    "        shave = 0\n",
    "    print(IMAGE_FILE[i])\n",
    "    print(IMAGE_GT_FILE[i])\n",
    "    res = evalimg(im_h_y, im_gt[i], shave)\n",
    "    res_all += [res]\n",
    "    print('evaluation against {}, rms={:.4f}, psnr={:.4f}'.format(IMAGE_GT_FILE[i], res['rmse'], res['psnr']))\n",
    "\n",
    "    ##Make Bicubic Image as comparison\n",
    "    im_h_b, im_h_b_y = upscale(im_l[i], UP_SCALE, nn=False)\n",
    "\n",
    "    if SHAVE==1:\n",
    "        shave = round(UP_SCALE)\n",
    "    else:\n",
    "        shave = 0\n",
    "    res_b = evalimg(im_h_b_y, im_gt[i], shave)\n",
    "    res_all_b += [res_b]\n",
    "    print('bicubic evaluation against {}, rms={:.4f}, psnr={:.4f}'.format(IMAGE_FILE[i], res_b['rmse'], res_b['psnr']))\n",
    "\n",
    "    ##DONE ADDED\n",
    "\n",
    "    # save\n",
    "    if save_SR:\n",
    "        img_name = os.path.splitext(os.path.basename(IMAGE_GT_FILE[i]))[0]\n",
    "        Image.fromarray(np.rint(im_h).astype(np.uint8)).save(f'{out_dir}/{img_name}_x{UP_SCALE}.png')\n",
    "        Image.fromarray(np.rint(im_h_b).astype(np.uint8)).save(f'{out_dir}/{img_name}_x{UP_SCALE}_bic.png')\n",
    "\n",
    "        \n",
    "print('mean SCN PSNR:', np.array([_['psnr'] for _ in res_all]).mean())\n",
    "print('mean bicubic PSNR:', np.array([_['psnr'] for _ in res_all_b]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f19e1d-4675-4e79-9f09-2b8ce295215b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
